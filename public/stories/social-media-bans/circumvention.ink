=== Circumvention_Reality ===
Here's what's already happening in Australia, where they've implemented similar bans: # diagram: circumvention_reality.png

About 1 in 3 parents are planning to help their children dodge the ban.

Think about that. The law says these platforms are too dangerous for children. But parents—who understand their kids' need for social connection—are actively helping them circumvent it.

Other kids are stealing their parents' IDs and scanning their faces without consent. Some are using photos of their siblings. A few have even tried using photos of their dog.

These aren't "bad kids" breaking the law for fun. They're socially isolated teenagers trying to stay connected with their friends.

*   [Why would parents help them bypass it?]
    Because they see what policymakers often miss.
    
    Their child is the only one in their friend group without access. They're excluded from group chats about homework, weekend plans, and inside jokes.
    
    They come home from school upset because everyone's talking about something that happened online that they missed.
    
    They can't participate in their school's sports team group chat or the drama club's planning discussions.
    
    The parent weighs the risks: the theoretical harms the law aims to prevent versus the very real social isolation their child is experiencing right now.
    
    Many choose connection.

*   [But they're breaking the law!]
    Yes. And that tells us something important.
    
    When a third of parents are willing to break the law to help their children, maybe the law is trying to solve the problem the wrong way.
    
    It's not that parents don't care about safety. They just recognize that social isolation has its own very real harms.

-
*   [What happens when kids bypass the ban?]
    That's where things get worse.
    -> Lying_About_Age

=== Lying_About_Age ===
To get past the age verification, children have to lie about their age. # diagram: age_lying_consequences.png

They say they're 18 or 21 instead of 14.

Seems harmless, right? They get access, everyone's happy.

Except:

Most platforms have specific safety features for users under 18:
• Restricted who can message them
• Limits on who can see their content  
• Warnings about inappropriate content
• Easier reporting for concerning behavior
• Content algorithms that avoid mature themes

When a 14-year-old claims to be 21, all those protections turn off.

The platform now treats them as an adult. The algorithm serves them adult content. Strangers can message them without restrictions. The safety rails disappear.

So the child is now more exposed to the very harms the ban was meant to prevent.

And when they turn 16 and can legally access social media? # diagram: sixteen_digital_id.png
If the face scan fails to verify their age, they'll need to provide ID.
This pushes teenagers—some as young as 16—toward digital ID systems.
Systems that track their location, browsing history, and create permanent surveillance records.

We're not just removing protections. We're funneling children into surveillance infrastructure.

*   [Can't we fix that somehow?]
    How? If the platform knows they're under 16, they'd be banned.
    
    The ban itself requires children to lie to access the service.
    
    And the lie removes their protections.
    
    We've created a system where the safety measure increases the danger.
    -> Hiding_Usage

*   [What about the digital ID concerns?]
    That's a critical issue. Government-run ID systems have their own serious problems.
    ~ navigateTo("digital-id")
    -> END

*   [What about parents monitoring them?]
    That's the other problem.
    -> Hiding_Usage

=== Hiding_Usage ===
Since the child isn't supposed to be on these platforms, they hide it. # diagram: hidden_usage.png

They delete apps before parents come home. They use private browsing. They create accounts their parents don't know about.

Normal teenage privacy behavior—but with a crucial difference:

When they encounter something troubling:
• Cyberbullying
• Grooming attempts  
• Explicit content
• Pressure to share inappropriate images

They can't tell their parents. Because that would reveal they're on the banned platform.

The child who needs help the most is the least likely to get it.

*   [This is getting worse, not better.]
    Exactly. The ban creates a false sense of security.
    -> False_Sense_Of_Security
*   [Surely we can find a better approach?]
    Yes. Let me show you what actually works.
    ~ navigateTo("better-parental-controls")
    -> END
