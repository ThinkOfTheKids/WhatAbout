=== False_Positives ===

= Innocent_Content
AI isn't perfect. With billions of messages scanned, even a tiny error rate causes huge problems. # diagram: false_positive_scale.png

If the system achieves 99.9% accuracy on WhatsApp's 100 billion daily messages, that's **100 million innocent messages flagged every day**.

These could be:
• Parents sharing bath-time photos with doctors
• Medical images sent to physicians
• Classical art or photography
• Couples sharing legal intimate photos
• Screenshots or memes matching patterns

*   [Is this already happening?]
    -> Real_World_Examples

*   [What happens to people who get falsely flagged?]
    -> The_Chilling_Effect

= Real_World_Examples
This is already happening. # diagram: google_photos_incident.png

A father took photos of his toddler's groin to send to a doctor for telehealth. Google Photos' CSAM detection flagged it.

Result:
• His account was disabled
• Lost emails, photos, contacts—everything
• Police investigated
• Even after being cleared, Google refused to restore his account

His only crime? Following his doctor's instructions.

*   [How does this affect people's behavior?]
    -> The_Chilling_Effect

*   [What about due process?]
    -> No_Due_Process

= The_Chilling_Effect
When people know they're being watched, they change their behavior. # diagram: chilling_effect.png

You might avoid discussing sensitive medical issues, sharing art that could be misinterpreted, or sending health information to your teenager.

You don't have to be doing anything wrong—just imagining the consequences of false accusation changes what you send.

*   [How does someone defend themselves?]
    -> No_Due_Process

*   [Does this expand beyond CSAM?]
    -> Scope_Creep.Starts_With_CSAM

*   [I've seen enough. What can I do?]
    -> Conclusion.Take_Action

= No_Due_Process
The scanning happens before you even send the message. # diagram: no_warrant.png

No warrant. No judge reviewing probable cause. No chance to challenge the accusation.

Traditional law enforcement needs a warrant to search your phone—they have to convince a judge there's good reason. But on-device scanning searches *everyone's* phone all the time, just in case.

It's like police searching every car at every intersection to make sure nobody's transporting anything illegal.

*   [How does this expand beyond CSAM?]
    -> Scope_Creep.Starts_With_CSAM

*   [What about the nudity filter requirement?]
    -> Nudity_Filter.Age_Verification_Requirement
    
*   [I've seen enough. What can I do?]
    -> Conclusion.Take_Action
