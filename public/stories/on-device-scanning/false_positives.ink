=== False_Positives ===

= Innocent_Content
AI is not perfect. And when you're scanning billions of messages, even a tiny error rate creates huge problems. # diagram: false_positive_scale.png

Let's say the scanning system has a 99.9% accuracy rate - sounds great, right?

If WhatsApp scans 100 billion messages per day worldwide, a 0.1% false positive rate means **100 million innocent messages flagged every day.**

These could be:
• Parents sharing bath-time photos of their children
• Medical images sent to doctors  
• Art photography or classical paintings
• Couples sharing intimate photos (legal between consenting adults)
• Memes or screenshots that happen to match patterns

-> Real_World_Examples

= Real_World_Examples
This isn't theoretical - it's already happening. # diagram: google_photos_incident.png

In 2022, a father took photos of his toddler's groin area to send to a doctor for a telehealth appointment. Google Photos' CSAM detection flagged the images. 

Result?
• His Google account was disabled
• He lost access to emails, photos, contacts - everything
• Police investigated him  
• Even after being cleared, Google refused to restore his account

His crime? Being a concerned parent following his doctor's instructions.

-> The_Chilling_Effect

= The_Chilling_Effect
When people know they're being watched, they change their behavior. # diagram: chilling_effect.png

This is called the "chilling effect" - and it's a recognized harm to free expression.

If you know your messages are being scanned:
• You might avoid discussing sensitive medical issues
• You might not share art or educational content that could be misinterpreted
• You might not send your teenager information about sexual health
• You might self-censor political or religious speech

And here's the thing: you don't have to be *doing* anything wrong to worry. You just have to imagine the consequences of being falsely accused.

-> No_Due_Process

= No_Due_Process
The scanning happens before you send the message. # diagram: no_warrant.png

There's no warrant. No judge reviewing whether there's probable cause to search your device.

Traditional law enforcement needs a warrant to search your phone. They need to convince a judge that there's good reason to believe you've committed a crime.

But with on-device scanning, *everyone's* phone is searched, all the time, just in case.

It's like having police search every car at every intersection, just to make sure nobody is transporting anything illegal.

*   [So how does this expand beyond CSAM?]
    -> Scope_Creep.Starts_With_CSAM

*   [What about that nudity filter requirement?]
    -> Nudity_Filter.Age_Verification_Requirement

*   [I've heard enough. What can I do?]
    -> Conclusion.Take_Action
