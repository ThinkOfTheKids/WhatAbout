=== Scope_Creep ===

= Starts_With_CSAM
Every surveillance system starts with a justification nobody argues with. # diagram: scope_creep_stages.png

"We're only using this for child abusers."
"We're only targeting terrorists."
"We're only stopping the worst criminals."

Then the scope expands.

*   [Has this pattern happened before?]
    -> Historical_Examples

*   [Is it already expanding in these proposals?]
    -> Already_Expanding

= Historical_Examples
We've seen this pattern: # diagram: mission_creep_examples.png

**Post-9/11 surveillance:**
Started as stopping terrorists. Became mass surveillance of all citizens (revealed by Snowden).

**UK's Investigatory Powers Act:**
Started as catching serious criminals. Councils now use it to spy on dog owners and verify school catchment areas.

**China's social credit system:**
Started as reducing fraud. Now tracks social media posts and restricts travel.

The pattern: build infrastructure for a noble cause, expand it to less serious cases, eventually weaponize for political control.

*   [Is it already expanding in these proposals?]
    -> Already_Expanding

*   [Who decides what's "harmful"?]
    -> Who_Decides

= Already_Expanding
The proposals are already expanding beyond CSAM. # diagram: expanding_definitions.png

The UK legislation includes vague language about:
• "Harmful content" (undefined)
• "Priority offences" (expandable list)
• "Content of concern" (government decides)

Once the infrastructure exists, adding new categories is trivial—just update the AI models.

No new legislation. No public debate. Just a quiet expansion.

*   [Who decides what's "harmful"?]
    -> Who_Decides

*   [How is this used in other countries?]
    -> International_Precedent

*   [Can't we just trust governments?]
    -> Who_Decides

= Who_Decides
Who decides what's "harmful"? # diagram: government_control.png

Today it's CSAM (which everyone agrees on).

Tomorrow it could be:
• Political dissent ("misinformation")
• LGBTQ+ content (banned in some countries)
• Religious or atheistic content (depends who's in power)
• Criticism of the government ("extremism")
• Union organizing or protest coordination
• Abortion information

The scanning system follows instructions. It doesn't care what it scans for.

*   [Is this already happening elsewhere?]
    -> International_Precedent

*   [Can surveillance ever be scaled back?]
    -> The_Ratchet_Effect

= International_Precedent
We know this isn't hypothetical. It's already happening. # diagram: global_surveillance.png

**China** scans messages for:
• References to Tiananmen Square
• Criticism of the government
• LGBTQ+ discussions

**Russia** scans for:
• Anti-war content
• Opposition to the government
• "LGBTQ propaganda"

**Saudi Arabia** scans for:
• Atheism
• Criticism of Islam

Once you build the infrastructure, authoritarian governments use it for political control. Even democracies—governments change. What seems reasonable today gets weaponized tomorrow.

*   [So we can never scale this back?]
    -> The_Ratchet_Effect

*   [I've heard enough. What can I do?]
    -> Conclusion.Take_Action

= The_Ratchet_Effect
Surveillance infrastructure only moves in one direction. # diagram: ratchet_effect.png

Once you build the ability to scan everyone's messages:
• Future governments will expand it
• New "threats" get added to the scanning list
• The infrastructure becomes permanent

You can't un-build it without losing the original use case. And there's always a crisis justifying "just a little more."

This is the "ratchet effect"—surveillance powers ratchet up but never down.

*   [What can I do about this?]
    -> Conclusion.Take_Action
    
*   [Tell me about false positives.]
    -> False_Positives.Innocent_Content
