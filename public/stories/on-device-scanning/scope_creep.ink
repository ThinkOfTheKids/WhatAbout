=== Scope_Creep ===

= Starts_With_CSAM
Every surveillance system starts with a justification nobody can argue with. # diagram: scope_creep_stages.png

"We're only using this to catch child abusers."
"We're only targeting terrorists."  
"We're only stopping the worst criminals."

And then, gradually, the scope expands.

-> Historical_Examples

= Historical_Examples
We've seen this pattern before: # diagram: mission_creep_examples.png

<>**Post-9/11 surveillance:**
• Started: "We need to stop terrorists"
• Became: Mass surveillance of all citizens (revealed by Edward Snowden)

<>**UK's Investigatory Powers Act:**
• Started: "We need to catch serious criminals"  
• Became: Councils using it to spy on dog owners and check school catchment areas

<>**China's social credit system:**
• Started: "We need to reduce fraud"
• Became: Tracking citizens' social media posts and restricting travel

The pattern is always the same:
1. Build the infrastructure for a noble purpose
2. Expand it to less serious cases
3. Eventually use it for political or social control

-> Already_Expanding

= Already_Expanding
We don't even have to wait for scope creep - it's already in the proposals. # diagram: expanding_definitions.png

The UK legislation doesn't just mention CSAM. It includes vague language about:
• "Harmful content" (undefined)
• "Priority offences" (expandable list)
• "Content of concern" (government decides)

Once the scanning infrastructure exists, adding new categories is trivial. Just update the AI models and the list of banned patterns.

No new legislation needed. No public debate. Just a quiet expansion of what gets flagged and reported.

-> Who_Decides

= Who_Decides
And here's the critical question: who decides what's "harmful"? # diagram: government_control.png

Today it might be CSAM (which everyone agrees is harmful).

Tomorrow it could be:
• Political dissent ("misinformation")
• LGBTQ+ content (already banned in some countries)
• Religious or atheistic content (depending on who's in power)
• Criticism of the government ("extremism")
• Union organizing or protest coordination
• Abortion information or resources

The scanning system doesn't care what it's scanning for. It just follows its instructions.

-> International_Precedent

= International_Precedent
We know this isn't hypothetical because it's already happening. # diagram: global_surveillance.png

<>**China** already scans messages for:
• References to Tiananmen Square
• Criticism of the government
• "Subversive" political content
• LGBTQ+ discussions

<>**Russia** scans for:
• Anti-war content
• Opposition to the government  
• "LGBTQ propaganda"

<>**Saudi Arabia** scans for:
• Atheism
• Criticism of Islam  
• Women's rights advocacy

Once you build the scanning infrastructure, authoritarian governments will absolutely use it for political control.

And even in democracies, governments change. What seems reasonable today might be weaponized tomorrow.

-> The_Ratchet_Effect

= The_Ratchet_Effect
Here's the problem with surveillance infrastructure: # diagram: ratchet_effect.png

It only moves in one direction.

Once you build the ability to scan everyone's messages:
• Future governments will expand it
• New "threats" will be added to the scanning list
• The infrastructure becomes permanent

You can't un-build it without losing the original use case. And there's always a crisis that justifies expanding it "just a little more."

This is called the "ratchet effect" - surveillance powers ratchet up but never ratchet down.

*   [What about false positives in all this?]
    -> False_Positives.Innocent_Content

*   [Tell me about the nudity filter requirement.]
    -> Nudity_Filter.Age_Verification_Requirement

*   [I've heard enough. What can I do?]
    -> Conclusion.Take_Action
