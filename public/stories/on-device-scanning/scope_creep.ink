=== Scope_Creep ===

= Starts_With_CSAM
Every surveillance system starts with a justification nobody argues with. # diagram: scope_creep_stages.jpg

"We're only using this for child abusers."
"We're only targeting terrorists."
"We're only stopping the worst criminals."

Then the scope expands.

*   [Has this pattern happened before?]
    -> Historical_Examples

*   [Is it already expanding in these proposals?]
    -> Already_Expanding

= Historical_Examples
We've seen this pattern: # diagram: mission_creep_examples.jpg

__Post-9/11 surveillance:__
Started as stopping terrorists. Became mass surveillance of all citizens (revealed by Snowden).

__UK's Investigatory Powers Act:__
Started as catching serious criminals. Councils now use it to spy on dog owners and verify school catchment areas.

__China's social credit system:__
Started as reducing fraud. Now tracks social media posts and restricts travel.

The pattern: build infrastructure for a noble cause, expand it to less serious cases, eventually weaponize for political control.

*   [Is it already expanding in these proposals?]
    -> Already_Expanding

*   [Who decides what's "harmful"?]
    -> Who_Decides

= Already_Expanding
The proposals are already expanding beyond CSAM. # diagram: expanding_definitions.jpg

The UK legislation includes vague language about:
• "Harmful content" (undefined)
• "Priority offences" (expandable list)
• "Content of concern" (government decides)

Once the infrastructure exists, adding new categories is trivial—just update the AI models.

No new legislation. No public debate. Just a quiet expansion.

*   [Who decides what's "harmful"?]
    -> Who_Decides

*   [How is this used in other countries?]
    -> International_Precedent

*   [Can't we just trust governments?]
    -> Who_Decides

= Who_Decides
Definitions of "harmful" can change over time. # diagram: government_control.jpg

Today's targets may be universally agreed upon. But scanning infrastructure, once built, can be updated to target new categories without legislation—just model updates.

The concern is that definitions expand based on political priorities.

*   [Is this already happening elsewhere?]
    -> International_Precedent

*   [Can surveillance ever be scaled back?]
    -> The_Ratchet_Effect

= International_Precedent
Scanning infrastructure is already used for content control in various countries. # diagram: global_surveillance.jpg

Once the technical capability exists, governments can expand its scope. What constitutes "harmful" varies by jurisdiction and can change with political leadership.

The infrastructure outlasts any single policy decision.

*   [So we can never scale this back?]
    -> The_Ratchet_Effect

*   [I've heard enough. What can I do?]
    -> Conclusion.Take_Action

= The_Ratchet_Effect
Surveillance infrastructure only moves in one direction. # diagram: ratchet_effect.jpg

Once you build the ability to scan everyone's messages:
• Future governments will expand it
• New "threats" get added to the scanning list
• The infrastructure becomes permanent

You can't un-build it without losing the original use case. And there's always a crisis justifying "just a little more."

This is the "ratchet effect"—surveillance powers ratchet up but never down.

*   [What can I do about this?]
    -> Conclusion.Take_Action
    
*   [Tell me about false positives.]
    -> False_Positives.Innocent_Content

